<!DOCTYPE html>
<!-- saved from url=(0069)https://sunprinces.github.io/interspeech2020-meta-learning/index.html -->
<html lang="en-us"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">
  <meta name="author" content="Daniel Li">
  <meta name="description" content="Meta Learning and Its Applications to Natural Language Processing">  
  <link rel="alternate" hreflang="en-us" href="https://meta-nlp-2021.github.io/index.html">  
  <meta name="theme-color" content="hsl(339, 90%, 68%)">
  <link rel="stylesheet" href="./meta-NLP_files/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="./meta-NLP_files/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
  <link rel="stylesheet" href="./meta-NLP_files/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">        
  <link rel="stylesheet" href="./meta-NLP_files/github.min.css" crossorigin="anonymous" title="hl-light" disabled="">
  <link rel="stylesheet" href="./meta-NLP_files/dracula.min.css" crossorigin="anonymous" title="hl-dark">
  <link rel="stylesheet" href="./meta-NLP_files/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
  <script src="./meta-NLP_files/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async=""></script>  
  <link rel="stylesheet" href="./meta-NLP_files/css">
  <link rel="stylesheet" href="./meta-NLP_files/academic.css">
  <meta property="twitter:card" content="summary">  
  <meta property="og:site_name" content="Meta Learning and Its Applications to Natural Language Processing">
  <meta property="og:url" content="https://meta-nlp-2021.github.io/index.html">
  <meta property="og:title" content="Meta Learning and Its Applications to Natural Language Processing">
  <meta property="og:description" content="Meta Learning and Its Applications to Natural Language Processing"><meta property="og:image" content="https://sunprinces.github.io/interspeech2020-meta-learning/images/icon_hu193fc9a26a32044892cac699d9253167_196637_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="https://sunprinces.github.io/interspeech2020-meta-learning/images/icon_hu193fc9a26a32044892cac699d9253167_196637_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  <meta property="og:updated_time" content="2020-06-01T13:00:00+00:00">

  <title>Meta Learning and Its Applications to Natural Language Processing</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="dark" style="opacity: 1; visibility: visible;">
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">
      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="https://meta-nlp-2021.github.io/index.html#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>
      <div id="search-box">
      </div>
    </section>
    <section class="section-search-results">
      <div id="search-hits">
      </div>
    </section>
  </div>
</aside>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="https://meta-nlp-2021.github.io/">Meta learning for NLP</a>
    </div>
    <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
    </button>    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="https://meta-nlp-2021.github.io/">Meta learning for NLP</a>
    </div>
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">
      <ul class="navbar-nav d-md-inline-flex">
        <li class="nav-item">
          <a class="nav-link" href="https://meta-nlp-2021.github.io/#calls" data-target="#calls"><span>Call for Papers</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://meta-nlp-2021.github.io/#reading" data-target="#reading"><span>Reading</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://meta-nlp-2021.github.io/#people" data-target="#people"><span>Organizers</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://meta-nlp-2021.github.io/#program" data-target="#program"><span>Program</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://meta-nlp-2021.github.io/#accepted_papers" data-target="#accepted_papers"><span>Accepted Papers</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link active" href="https://meta-nlp-2021.github.io/#contact" data-target="#contact"><span>Contact</span></a>
        </li>
      </ul>
    </div>
    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="https://meta-nlp-2021.github.io/index.html#"><i class="fas fa-sun" aria-hidden="true"></i></a>
      </li>
    </ul>
  </div>
</nav>
<span class="js-widget-page d-none"></span>
  <section id="intro" class="home-section wg-blank   " style="padding: 20px 0 20px 0;">
    <div class="container">
      <div class="row">
        <div class="col-lg-12">
          <h1>Meta Learning and Its Applications to Natural Language Processing</h1>
          <!--weight:  5-->
          <p><strong>Workshop proposed at EACL/NAACL/ACL/EMNLP 2021</strong></p>
          <h2 id="description">Description</h2>
          <p>Deep learning based natural language processing (NLP) has become the mainstream of research in recent years and significantly outperforms conventional methods. However, deep learning models are notorious for being data and computation hungry. These downsides limit such models' application from deployment to different domains, languages, countries, or styles, since collecting in-genre data and model training from scratch are costly. The long-tail nature of human language makes challenges even more significant.</p>

          <p>Meta-learning, or ‘Learning to Learn’, aims to learn better learning algorithms, including better parameter initialization, optimization strategy, network architecture, distance metrics, and beyond (Finn et al., 2017; Snell et al., 2017; Vinyals et al.,2016; Andrychowicz et al., 2016; Chen et al., 2020). Meta-learning has been shown to allow faster fine-tuning, converge to better performance, and achieve outstanding results for few-shot learning in many applications (Suris et al., 2019; Bose et al., 2019). Meta-learning is one of the most important new techniques in machine learning in recent years. 
          There is a related tutorial in <a href="https://sites.google.com/view/icml19metalearning">ICML 2019</a> and a related <a href="http://cs330.stanford.edu/">course at Stanford</a>, but most of the example applications given in these materials are about image processing. It is believed that meta-learning has excellent potential to be applied in NLP, and some works have been proposed with notable achievements in several relevant problems, e.g., relation extraction, machine translation, and dialogue generation and state tracking (Madotto et al., 2019; Obamuyide and Vlachos, 2019; Bansal et al., 2019; Chen et al., 2019; Gu et al., 2018; Yan et al., 2020; Luo et al., 2020; Shah et al., 2019). However, it does not catch the same level of attention as in the image processing community.</p>

          <p>This workshop will bring concentrated discussions on meta-learning for the field of NLP via several invited talks, oral and poster sessions with high-quality papers, and a panel of leading researchers from industry and academia. Alongside research work on new meta-learning methods, data, applications, and results, this workshop will call for novel work on understanding, analyzing, and comparing different meta-learning approaches for NLP. The workshop aims to 1) review existing and inspire new meta-learning methods and results, 2) motivate the application of meta-learning approaches to more NLP problems, 3) motivate works on comparing different meta-learning methods and comparing meta-learning to other transfer learning methods that have been long utilized for low-resource NLP, 4) encourage communication within the field of NLP to sharing knowledge, ideas, and data for meta-learning, and encourage future collaboration to inspire innovation.</p>
          <!--<div class="alert alert-note">
            <div>
              &ndash;&gt;</p>
          <!--Important information-->
          <!--
            </div>
          </div>
          -->
        </div>
      </div>
    </div>
  </section>
  <section id="calls" class="home-section wg-blank   " style="padding: 20px 0 20px 0;">
    <div class="container">
      <div class="row">
        <div class="col-12 col-lg-4 section-heading">
          <h1>Call for Papers</h1>
        </div>
        <div class="col-12 col-lg-8">
          <!--weight: 15-->
          <p>TBD</p>
          <div class="alert alert-note">
            <div>
              <strong>Important Dates</strong><p></p>
              <ul>
                <li>TBD</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section id="reading" class="home-section wg-blank   " style="padding: 20px 0 20px 0;">
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      <h1>Reading</h1>
      
      <p>Meta learning is one of the fastest growing research areas in the deep learning scope. However there is no standard definition for meta learning. Usually the main goal is to design models that can learn new tasks rapidly with few in domain training examples, by having models to pre-learn from many, relevant or not, training tasks in a way that the models are easy to be generalized to new tasks. For better understanding the scope of meta learning, we provide several online courses and papers describing the works falling into the area. These works are just for showcasing, and we definitely encourage people with research not covered here but sharing the same goal mentioned above to submit.</p>
<h3 id="online-courses">Online Courses</h3>
<ul>
<li>
<a href="http://cs330.stanford.edu/" target="_blank" rel="noopener">CS 330: Deep Multi-Task and Meta Learning</a>
</li>
<li>
<a href="https://youtu.be/wurPYalweeo" target="_blank" rel="noopener">Hung-Yi Lee’s Lecture</a>
 (in Mandarin)</li>
</ul>
<h3 id="papers">Papers</h3>
<h4 id="meta-learning-technology">Meta Learning Technology</h4>
<ul>
<li>Learning to Initialize:
<ul>
<li>Chelsea Finn, Pieter Abbeel, and Sergey Levine, “Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks”, ICML, 2017</li>
<li>Sebastian Flennerhag, Pablo G. Moreno, Neil D. Lawrence, Andreas Damianou, Transferring Knowledge across Learning Processes, ICLR, 2019</li>
</ul>
</li>
<li>Learning to optimize:
<ul>
<li>Sachin Ravi, Hugo Larochelle, Optimization as a model for few-shot learning, ICLR, 2017</li>
<li>Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W. Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, Nando de Freitas, Learning to learn by gradient descent by gradient descent, NIPS, 2016</li>
</ul>
</li>
<li>Learning to compare
<ul>
<li>Jake Snell, Kevin Swersky, Richard S. Zemel, Prototypical Networks for Few-shot Learning, NIPS, 2017</li>
<li>Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra, Matching Networks for One Shot Learning, NIPS, 2016</li>
<li>Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H.S. Torr, Timothy M. Hospedales, Learning to Compare: Relation Network for Few-Shot Learning, CVPR, 2018</li>
</ul>
</li>
<li>Learning the whole learning algorithm
<ul>
<li>Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap, Meta-Learning with Memory-Augmented Neural Networks, ICML, 2016</li>
<li>Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel, A Simple Neural Attentive Meta-Learner, ICLR, 2018</li>
</ul>
</li>
<li>Network architecture search:
<ul>
<li>RL based
<ul>
<li>Barret Zoph, Quoc V. Le, Neural Architecture Search with Reinforcement Learning, ICLR 2017</li>
<li>Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc V. Le,  Learning Transferable Architectures for Scalable Image Recognition, CVPR, 2018</li>
<li>Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, Jeff Dean, Efficient Neural Architecture Search via Parameter Sharing, ICML, 2018</li>
</ul>
</li>
<li>Evolution based
<ul>
<li>Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc Le, Alex Kurakin, Large-Scale Evolution of Image Classifiers, ICML 2017</li>
<li>Esteban Real, Alok Aggarwal, Yanping Huang, Quoc V Le, Regularized Evolution for Image Classifier Architecture Search, AAAI, 2019</li>
<li>Hanxiao Liu, Karen Simonyan, Oriol Vinyals, Chrisantha Fernando, Koray Kavukcuoglu, Hierarchical Representations for Efficient Architecture Search, ICLR, 2018</li>
</ul>
</li>
<li>Supernetwork based
<ul>
<li>Hanxiao Liu, Karen Simonyan, Yiming Yang, DARTS: Differentiable Architecture Search, ICLR, 2019</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="applications-to-human-language-technology">Applications to Natural language understanding:</h4>

<ul>
<li><strong>[Bansal, et al., arXiv’19]</strong> Trapit Bansal, Rishikesh Jha, Andrew McCallum, Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks, arXiv, 2019</li>
<li><strong>[Bose, et al., arXiv’19]</strong> Avishek Joey Bose, Ankit Jain, Piero Molino, William L. Hamilton, Meta-Graph: Few shot Link Prediction via Meta Learning, arXiv, 2019</li>
<li><strong>[Campagna, et al., ACL’20]</strong> Giovanni Campagna, Agata Foryciarz, Mehrad Moradshahi, Monica Lam, Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking, ACL 2020</li>
<li><strong>[Chen, et al., EMNLP’19]</strong> Mingyang Chen, Wen Zhang, Wei Zhang, Qiang Chen, Huajun Chen, Meta Relational Learning for Few-Shot Link Prediction in Knowledge Graphs, EMNLP 2019</li>
<li><strong>[Chen, et al., INTERSPEECH'20]</strong> Yi-Chen Chen, Jui-Yang Hsu, Cheng-Kuang Lee, Hung-yi Lee, DARTS-ASR: Differentiable architecture search for multilingual speech recognition and adaptation, INTERSPEECH 2020</li>
<li><strong>[Chen, et al., ACL’20]</strong> Zhiyu Chen, Harini Eavani, Wenhu Chen, Yinyin Liu, William Yang Wang, Few-Shot NLG with Pre-Trained Language Model, ACL 2020</li>
<li><strong>[Chien, et al., INTERSPEECH’19]</strong> Jen-Tzung Chien, Wei Xiang Lieow, Meta Learning for Hyperparameter Optimization in Dialogue System, INTERSPEECH, 2019</li>
<li><strong>[Coope, et al., ACL’20]</strong> Samuel Coope, Tyler Farghly, Daniela Gerz, Ivan Vulić, Matthew Henderson, Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations, ACL 2020</li>
<li><strong>[Dou, et al., EMNLP’19]</strong> Zi-Yi Dou, Keyi Yu, Antonios Anastasopoulos, Investigating Meta-Learning Algorithms for Low-Resource Natural Language Understanding Tasks, EMNLP 2019</li>
<li><strong>[Geng, et al., EMNLP’19]</strong> Ruiying Geng, Binhua Li, Yongbin Li, Xiaodan Zhu, Ping Jian, Jian Sun, Induction Networks for Few-Shot Text Classification, EMNLP, 2019</li>
<li><strong>[Geng, et al., ACL’20]</strong> Ruiying Geng, Binhua Li, Yongbin Li, Jian Sun, Xiaodan Zhu, Dynamic Memory Induction Networks for Few-Shot Text Classification, ACL 2020</li>
<li><strong>[Gu, et al., EMNLP’18]</strong> Jiatao Gu, Yong Wang, Yun Chen, Kyunghyun Cho, Victor O.K. Li, Meta-Learning for Low-Resource Neural Machine Translation, EMNLP, 2018</li>
<li><strong>[Guo, et al., ACL’19]</strong> Daya Guo, Duyu Tang, Nan Duan, Ming Zhou, Jian Yin, Coupling Retrieval and Meta-Learning for Context-Dependent Semantic Parsing, ACL, 2019</li>
<li><strong>[Hou, et al., ACL’20]</strong> Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu, Ting Liu, Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network, ACL 2020</li>
<li><strong>[Hu, et al., ACL’19]</strong> Ziniu Hu, Ting Chen, Kai-Wei Chang, Yizhou Sun, Few-Shot Representation Learning for Out-Of-Vocabulary Words, ACL 2019</li>
<li><strong>[Huang, et al., NAACL’18]</strong> Po-Sen Huang, Chenglong Wang, Rishabh Singh, Wen-tau Yih, Xiaodong He, Natural Language to Structured Query Generation via Meta-Learning, NAACL 2018</li>
<li><strong>[Huang, et al., ACL’20]</strong> Yi Huang, Junlan Feng, Min Hu, Xiaoting Wu, Xiaoyu Du, Shuo Ma, Meta-Reinforced Multi-Domain State Generator for Dialogue Systems, ACL 2020</li>
<li><strong>[Kim, et al., ACL’20]</strong> Hwichan Kim, Tosho Hirasawa, Mamoru Komachi, Zero-shot North Korean to English Neural Machine Translation by Character Tokenization and Phoneme Decomposition, ACL 2020</li>
<li><strong>[Luo, et al., INTERSPEECH'20]</strong> Hongyin Luo, Shang-Wen Li, James Glass, Prototypical q networks for automatic conversational diagnosis and few-shot new disease adaption, INTERSPEECH 2020</li>
<li><strong>[Lv, et al., EMNLP’19]</strong> Xin Lv, Yuxian Gu, Xu Han, Lei Hou, Juanzi Li, Zhiyuan Liu, Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations, EMNLP 2019</li>
<li><strong>[Madotto, et al., ACL’19]</strong> Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu, Pascale Fung, Personalizing Dialogue Agents via Meta-Learning, ACL 2019</li>
<li><strong>[Mohtarami, et al., EMNLP’19]</strong> Mitra Mohtarami, James Glass, Preslav Nakov, Contrastive language adaptation for cross-lingual stance detection, EMNLP 2019</li>
<li><strong>[Mu, et al., ACL’20]</strong> Jesse Mu, Percy Liang, Noah Goodman, Shaping Visual Representations with Language for Few-shot Classification, ACL 2020</li>
<li><strong>[Obamuyide, et al., ACL’19]</strong> Abiola Obamuyide, Andreas Vlachos, Model-Agnostic Meta-Learning for Relation Classification with Limited Supervision, ACL 2019</li>
<li><strong>[Qian, et al., ACL’19]</strong> Kun Qian, Zhou Yu, Domain Adaptive Dialog Generation via Meta Learning, ACL 2019</li>
<li><strong>[Shah, et al., ACL’19]</strong> Darsh Shah, Raghav Gupta, Amir Fayazi, Dilek Hakkani-Tur, Robust zero-shot cross-domain slot filling with example values, ACL 2019</li>
<li><strong>[Song, et al., ACL’20]</strong> Yiping Song, Zequn Liu, Wei Bi, Rui Yan, Ming Zhang, Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks, ACL 2020</li>
<li><strong>[Sun, et al., EMNLP’18]</strong> Jingyuan Sun, Shaonan Wang, Chengqing Zong, Memory, Show the Way: Memory Based Few Shot Word Representation Learning, EMNLP 2018</li>
<li><strong>[Sun, et al., EMNLP’19]</strong> Shengli Sun, Qingfeng Sun, Kevin Zhou, Tengchao Lv, Hierarchical Attention Prototypical Networks for Few-Shot Text Classification, EMNLP 2019</li>
<li><strong>[Surís, et al., arXiv’19]</strong> Dídac Surís, Dave Epstein, Heng Ji, Shih-Fu Chang, Carl Vondrick, Learning to Learn Words from Narrated Video, arXiv, 2019</li>
<li><strong>[Tan, et al., EMNLP’19]</strong> Ming Tan, Yang Yu, Haoyu Wang, Dakuo Wang, Saloni Potdar, Shiyu Chang, Mo Yu, Out-of-Domain Detection for Low-Resource Text Classification Tasks, EMNLP 2019</li>
<li><strong>[Wang, et al., EMNLP’19]</strong> Zihao Wang, Kwun Ping Lai, Piji Li, Lidong Bing, Wai Lam, Tackling Long-Tailed Relations and Uncommon Entities in Knowledge Graph Completion, EMNLP 2019</li>
<li><strong>[Winata, et al., ACL’20]</strong> Genta Indra Winata, Samuel Cahyawijaya, Zhaojiang Lin, Zihan Liu, Peng Xu, Pascale Fung, Meta-Transfer Learning for Code-Switched Speech Recognition, ACL 2020</li>
<li><strong>[Wu, et al., EMNLP’19]</strong> Jiawei Wu, Wenhan Xiong, William Yang Wang, Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label Classification, EMNLP 2019</li>
<li><strong>[Wu, et al., AAAI’20]</strong> Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, Börje F. Karlsson, Biqing Huang, Chin-Yew Lin, Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with Minimal Resources, AAAI 2020</li>
<li><strong>[Xiong, et al., EMNLP’18]</strong> Wenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang, One-Shot Relational Learning for Knowledge Graphs, EMNLP 2018</li>
<li><strong>[Yan, et al., ACL’20]</strong> Guangfeng Yan, Lu Fan, Qimai Li, Han Liu, Xiaotong Zhang, Xiao-Ming Wu, Albert Y.S. Lam, Unknown Intent Detection Using Gaussian Mixture Model with an Application to Zero-shot Intent Classification, ACL 2020</li>
<li><strong>[Yan, et al., ACL’20]</strong> Ming Yan, Hao Zhang, Di Jin, Joey Tianyi Zhou, Multi-source meta transfer for low resource multiple-choice question answering, ACL 2020</li>
<li><strong>[Ye, et al., ACL’20]</strong> Zhiquan Ye, Yuxia Geng, Jiaoyan Chen, Jingmin Chen, Xiaoxiao Xu, SuHang Zheng, Feng Wang, Jun Zhang, Huajun Chen, Zero-shot Text Classification via Reinforced Self-training, ACL 2020</li>
<li><strong>[Ye, et al., ACL’19]</strong> Zhi-Xiu Ye, Zhen-Hua Ling, Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification, ACL 2019</li>
<li><strong>[Yu, et al., ACL’20]</strong> Changlong Yu, Jialong Han, Haisong Zhang, Wilfred Ng, Hypernymy Detection for Low-Resource Languages via Meta Learning, ACL 2020</li>
<li><strong>[Yu, et al., ACL’18]</strong> Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang, Bowen Zhou, Diverse Few-Shot Text Classification with Multiple Metrics, ACL 2018</li>
<li><strong>[Zhang, et al., ACL’20]</strong> Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation, ACL 2020</li>
<li><strong>[Zhao, et al. EMNLP’19]</strong> Zhenjie Zhao, Xiaojuan Ma, Text Emotion Distribution Learning from Small Sample: A Meta-Learning Approach, EMNLP 2019</li>


</ul>
    </div>
</div>
    </div>
  </section>
  

  <section id="people" class="home-section wg-people   ">
    <div class="container">
      <div class="row justify-content-center people-widget">  
        <div class="col-md-12 section-heading">
          <h1>Organizers</h1>
        </div>
        <div class="col-md-12">
          <h2>&nbsp;</h2>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <!-- TODO -->
            <a href="https://meta-nlp-2021.github.io/authors/hungyi/"><img class="avatar avatar-circle" src="./meta-NLP_files/hungyi.jpg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Hung-Yi Lee</h2>
            <h3>National Taiwan University</h3>
            <h3>Associate Professor</h3>
          </div>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <a href="https://meta-nlp-2021.github.io/authors/mitra/"><img class="avatar avatar-circle" src="./meta-NLP_files/mitra.jpg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Mitra Mohtarami</h2>
            <h3>Massachusetts Institute of Technology</h3>
            <h3>Research Scientist</h3>
          </div>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <a href="https://meta-nlp-2021.github.io/authors/shangwen/"><img class="avatar avatar-circle" src="./meta-NLP_files/daniel.jpg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Shang-Wen Li</h2>
            <h3>Amzaon web services AI</h3>
            <h3>Senior Applied Scientist</h3>
          </div>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <a href="https://meta-nlp-2021.github.io/authors/di/"><img class="avatar avatar-circle" src="./meta-NLP_files/di.jpeg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Di Jin</h2>
            <h3>Amazon Alexa AI</h3>
            <h3>Applied Scientist</h3>
          </div>
        </div>

        <div class="col-12 col-sm-3 people-person">
            <!-- TODO -->
            <a href="https://meta-nlp-2021.github.io/authors/mandy/"><img class="avatar avatar-circle" src="./meta-NLP_files/mandy.jpg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Mandy Korpusik</h2>
            <h3>Loyola Marymount University</h3>
            <h3>Assistant Professor</h3>
          </div>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <a href="https://meta-nlp-2021.github.io/authors/annie/"><img class="avatar avatar-circle" src="./meta-NLP_files/annie.jpg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Annie Dong</h2>
            <h3>Amazon Alexa AI</h3>
            <h3>Applied Scientist</h3>
          </div>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <a href="https://meta-nlp-2021.github.io/authors/ngoc/"><img class="avatar avatar-circle" src="./meta-NLP_files/thang.jpg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Ngoc Thang Vu</h2>
            <h3>University of Stuttgart</h3>
            <h3>Professor</h3>
          </div>
        </div>
        <div class="col-12 col-sm-3 people-person">
            <a href="https://meta-nlp-2021.github.io/authors/dilek/"><img class="avatar avatar-circle" src="./meta-NLP_files/dilek.jpeg" alt="Avatar"></a>
          <div class="portrait-title">
            <h2>Dilek Hakkani-Tur</h2>
            <h3>Amazon Alexa AI</h3>
            <h3>Senior Principal Scientist</h3>
          </div>
        </div>






      </div>
    </div>
  </section>

  <section id="program" class="home-section wg-blank   " style="padding: 20px 0 20px 0;">
    <div class="container">
      <div class="row">
        <div class="col-lg-12">
          <h1>Program</h1>
          <p>TBD</p>
        </div>  
      </div>
    </div>
  </section>

  <section id="accepted_papers" class="home-section wg-blank   " style="padding: 20px 0 20px 0;">
    <div class="container">
      <div class="row">
        <div class="col-lg-12">
          <h1>Accepted Papers</h1>
          <p>TBD</p>
        </div>
      </div>
    </div>
  </section>

  <section id="contact" class="home-section wg-contact   ">
    <div class="container">
      <div class="row contact-widget">
        <div class="col-12 col-lg-4 section-heading">
          <h1>Contact</h1>
        </div>
        <div class="col-12 col-lg-8">
          If you have any questions or feedback, please feel free to contact us
          <ul class="fa-ul">
            <li>
              <i class="fa-li fas fa-envelope fa-2x" aria-hidden="true"></i>
              <span id="person-email"><a href="mailto:tbd">TBD</a></span>
              <!--<span id="person-email"><a href="mailto:is.2020.meta.learning@gmail.com">is.2020.meta.learning@gmail.com</a></span>-->
            </li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <script src="./meta-NLP_files/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
  <script src="./meta-NLP_files/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
  <script src="./meta-NLP_files/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
  <script src="./meta-NLP_files/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="./meta-NLP_files/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
  <script src="./meta-NLP_files/r.min.js"></script>
  <script src="./meta-NLP_files/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
  <script>const code_highlighting = true;</script>
  <script src="./meta-NLP_files/academic.min.e5c8525332f417fe3589df9a6b25b6c4.js"></script>
  
  <div class="container">
    <footer class="site-footer">
      <p class="powered-by">
        © [Conference name] · 
        Powered by the
        <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
        <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>.
        <span class="float-right" aria-hidden="true">
          <a href="https://meta-nlp-2021.github.io/index.html#" class="back-to-top">
            <span class="button_icon">
              <i class="fas fa-chevron-up fa-2x"></i>
            </span>
          </a>
        </span>
      </p>
    </footer>
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">×</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="https://meta-nlp-2021.github.io/index.html#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="https://meta-nlp-2021.github.io/index.html#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


</body></html>